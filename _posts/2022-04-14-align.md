---
title: ALIGN
tags: multi-modal
author: lsh
---

(ICML 21) Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision

<!--more-->

---
 
## Abstract

Conceptual Captions, MSCOCO 그리고 CLIP을 학습하는 데 사용한 데이터셋들은 non-trival data collection과 cleaning process를 가지고 있습니다. 이러한 값비싼 데이터셋 Curation 과정은 데이터셋 크기를 제한하고 학습된 모델의 크기가 커지는 것을 방해합니다. 본 논문에서 제안하는 **Dual-encoder** 구조는 contrastive loss로 정렬된 visual과 language 사이의 representation을 배웁니다. **noise한 텍스트 데이터의 corpus를 증가시키는 간단한 학습 전략**은 복잡한 텍스트, 텍스트+이미지 쿼리의 cross-modality search를 가능하게 합니다.  

## Introduction
