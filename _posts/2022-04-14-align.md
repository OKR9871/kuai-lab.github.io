---
title: ALIGN
tags: multi-modal
author: lsh
---

(ICML 21) Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision

<!--more-->

---
 
## 0. Abstract

Conceptual Captions, MSCOCO 그리고 CLIP을 학습하는 데 사용한 데이터셋들은 non-trival data collection과 cleaning process를 가지고 있습니다. 이러한 값비싼 데이터셋 Curation 과정은 데이터셋 크기를 제한하고 학습된 모델의 크기가 커지는 것을 방해합니다. 본 논문에서 제안하는 **Dual-encoder** 구조는 contrastive loss로 정렬된 visual과 language 사이의 representation을 배웁니다. **noise한 텍스트 데이터의 corpus를 증가시키는 간단한 학습 전략**은 복잡한 텍스트, 텍스트+이미지 쿼리의 cross-modality search를 가능하게 합니다.  

## 1. Introduction

### Why do we need noisy data?
Conceptual Captions, Visual Genome Dense Captions 그리고 ImageBERT는 human annotation, semantic parsing, cleaning and balancing 작업이 들어가기 때문에 데이터셋을 만드는데 많은 노력이 들어갑니다. 데이터 셋 역시 10M 예시 정도 밖에 만들 수 없는 단점이 있습니다. 이는 NLP pre-training에 사용되는 데이터셋의 개수에 비하면 매우 작습니다. 

### Noisy image alt-text pairs
따라서 vision-language representation learning에 필요한 데이터 개수를 증가시키기 위하여, one billion noisy image alt-text pairs를 leverage, 사용합니다. 다양한 데이터 클리닝 전략을 사용하는 것 대신에 Conceptual Captions Dataset에 오직 frequency-based filtering 전략만을 사용합니다. 이러한 exascale dataset으로 사전 학습한 모델은 다양한 task에서 강력한 성능을 가집니다. 

![image](https://1.bp.blogspot.com/-95CxjbAC6nM/YJqTiXqr7AI/AAAAAAAAHlg/iG3kb9mxck8o86epEJHkUF7V9v5sc3SdgCLcBGAsYHQ/w640-h334/image5.png)

### Contribution
Dual-encoder 구조로 visual과 language representation이 Shared latent embedding space를 가지도록 합니다. **ALIGN: A Large-scale ImaGe and Noisy-embedding** 은 Flicker30K과 MSCOCO에서 zero-shot 그리고 fine-tuned R@1 metrics에서 SOTA 성능을 달성합니다. 또한 이미지넷에서 88.64% top-1 acc 성능을 달성합니다. 

## 2. Related Work
CLIP과 매우 접근이 유사하지만 다른 점은 training data입니다. CLIP은 English Wikipedia로부터 데이터셋을 수집하지만 ALIGN은 raw alt-text data로부터 나온 거의 모든 image-text pair 데이터셋을 사용합니다. 이는 natural한 distribution을 따를 수 있는 장점이 있습니다.

## 3. A Large-Scale Noisy Image-Text Dataset

데이터 크기를 증가하는 것이 본 논문이 주 목적이므로 cleaning step의 대부분을 완화하는 전략을 사용합니다. 

### Image-based filtering
가로, 세로 중 더 짧은 길이가 200보다 큰 이미지를 사용합니다. 또한 aspect가 3보다 작은 이미지를 사용합니다.

### Text-based filtering
1920X1080, alt_img, cristina와 같이 10장의 이미지보다 더 많이 공유된 alt-texts를 제외합니다. 3 보다 작은 그리고 20보다 큰 unigram도 삭제합니다. 

## 4. Pre-training and Task Transfer

### 4.1 Pre-training on Noisy Image-Text Pairs












